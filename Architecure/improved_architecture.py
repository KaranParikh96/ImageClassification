# -*- coding: utf-8 -*-
"""Copy of Final Project

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x8cf3CEszj9nHxpKomm5nfJki88L18Ea

Importing necessary modules:
"""

import numpy as np
import torch
import torch.nn as nn
import torchvision
import torch.nn.functional as F
from torchvision.transforms import Compose 
import matplotlib.pyplot as plt
torch.cuda.empty_cache()

"""Downloading and augmenting the training and testing data:"""

from torchvision.transforms import transforms
train_transform = Compose([
    transforms.RandomHorizontalFlip(p=0.5), #flipping half of the training dataset horizontally
    transforms.RandomCrop(32, padding=4,padding_mode="reflect"), #doing a random crop with padding=4
    transforms.ToTensor(), #converting all input training images to tensors
    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]) #normalizing tensor values
])

test_transform = Compose([
    transforms.ToTensor(), #converting all input test images to tensors
    transforms.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]) #normalizing tensor values
])
#setting transform to the transformations defined above 
trainingdata = torchvision.datasets.CIFAR10('./CIFAR10/',train=True,download=True, transform=train_transform) #train=true for training data only
testdata = torchvision.datasets.CIFAR10('./CIFAR10/',train=False,download=True,transform=test_transform)

"""Printing the length of the training data and testing data:"""

print("Training size: ",len(trainingdata)) #printing the train size
print("Test size: ",len(testdata)) #printing the test data size

"""Loading the data:"""

#keeping batch_size=64 for both train and test data

trainDataLoader = torch.utils.data.DataLoader(trainingdata,batch_size=64,shuffle=True) 
#shuffle=true for shuffling training data for better generalization

testDataLoader = torch.utils.data.DataLoader(testdata,batch_size=64,shuffle=False)

# print(len(trainDataLoader.dataset))

# trainDataLoader.batch_sampler

"""Taking a sample image from the training data to check size and its output:"""

# image, label = trainingdata[0]
# print(image.shape, label)
# # print(image)
# image1 = image.numpy().transpose(1,2,0).squeeze()
# plt.imshow(image1)
# plt.show()

"""Each Residual Block:"""

#BasicBlock(in_planes, planes, stride)
class BasicBlock(nn.Module):
    #RESIDUAL BLOCK CREATED HERE!!! 
    def __init__(self, in_planes, planes, stride=1):
        super(BasicBlock, self).__init__()

        # if stride!=1 or in_planes=64:
        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1,bias=False)
        self.bn1 = nn.BatchNorm2d(planes)
        self.conv2 = nn.Conv2d(planes, planes//2, kernel_size=1, stride=1,bias=False)
        self.bn2 = nn.BatchNorm2d(planes//2)
        self.conv3 = nn.Conv2d(planes//2, planes//2, kernel_size=3, stride=1, padding=1,bias=False)
        self.bn3 = nn.BatchNorm2d(planes//2)
        self.conv4 = nn.Conv2d(planes//2, planes, kernel_size=1, stride=1, bias=False)
        self.bn4 = nn.BatchNorm2d(planes)
        
        # else:
        #   self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1,bias=False)
        #   self.bn1 = nn.BatchNorm2d(planes)
        #   self.conv2 = nn.Conv2d(planes, planes//2, kernel_size=1, stride=1,bias=False)
        #   self.bn2 = nn.BatchNorm2d(planes//2)
        #   self.conv3 = nn.Conv2d(planes//2, planes//2, kernel_size=3, stride=1, padding=1,bias=False)
        #   self.bn3 = nn.BatchNorm2d(planes//2)
        #   self.conv4 = nn.Conv2d(planes//2, planes, kernel_size=1, stride=1, bias=False)
        #   self.bn4 = nn.BatchNorm2d(planes)


          
    #DOTTED LINK RESNET!!!
        self.shortcut = nn.Sequential()
        if stride != 1 or in_planes != planes: 
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(planes)
            )

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        # print("conv1")
        # print("conv1",out.shape)
        out = self.bn2(self.conv2(out))
        # print("conv2")
        # print("conv2",out.shape)
        out = self.bn3(self.conv3(out))
        out = self.bn4(self.conv4(out))
        # out = self.bn5(self.conv5(out))
        # out =self.bn6(self.conv6(out))
        # print("conv3")
        # print("conv3",out.shape)
        out += self.shortcut(x)
        out = F.relu(out)
        return out



class ResNet(nn.Module):
    def __init__(self, block, num_blocks, num_classes=10):
        #BLOCK= 1 basicblock/ 1 residual block
        #num_blocks=[2,2,2,2] 
        #num_classes=10
        #planes here mean channels
        super(ResNet, self).__init__()
        self.in_planes = 64

        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
        #in_planes=3, planes=64, kernel/filter size=3x3, stride=1, padding=1
        self.bn1 = nn.BatchNorm2d(64)
        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)

        # print(self.layer1)
        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)
        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)
        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)
        self.linear = nn.Linear(512, num_classes)

    def _make_layer(self, block, planes, num_blocks, stride):
        strides = [stride] + [1]*(num_blocks-1) 
        #[1,1]
        #[2,1]
        #[2,1,1]
        #[2]
        layers = []
        # print(f"Strides:{strides}")
        for stride in strides:
            layers.append(block(self.in_planes, planes, stride))
            self.in_planes = planes
        return nn.Sequential(*layers)

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))
        # print(out.shape)
        out = self.layer1(out)
        # print("layer1 out=",out.shape)
        out = self.layer2(out)
        # print("layer2 out=",out.shape)
        out = self.layer3(out)
        # print("layer3 out=",out.shape)
        out = self.layer4(out)
        out = F.avg_pool2d(out, 4)
        # print("avgpool out=",out.shape)
        out = out.view(out.size(0), -1)
        # print("layer5 out=",out.shape)
        out = self.linear(out)
        return F.log_softmax(out, dim=1)

def project1_model():
    return ResNet(BasicBlock, [2, 2, 3, 1])

model = project1_model().cuda()
model

from torch.optim import optimizer
loss = torch.nn.NLLLoss()
# optimizer = torch.optim.SGD(model.parameters(), lr=0.001,momentum = 0.9)
optimizer=torch.optim.Adagrad(model.parameters())
#optimizer=torch.optim.Adam(model.parameters())
#optimizer=torch.optim.Adamax(model.parameters())
#optimizer=torch.optim.SGD(model.parameters(), lr=0.001, nesterov=True)

def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

print(count_parameters(model))

train_loss_hist  = []
test_loss_hist = []
train_acc_history = [] 
test_acc_history = [] 


for epoch in range(100):
  train_loss =  0.0
  test_loss = 0.0
  correct_points_train = 0 
  correct_points_test = 0 



  for i,data in enumerate(trainDataLoader):
    images,labels = data
    images = images.cuda()
    labels = labels.cuda()
    optimizer.zero_grad()
    y_pred = model(images)
    fit = loss(y_pred, labels)
    fit.backward()
    optimizer.step()
    train_loss += fit.item()
    # print('loss:-',fit)
    # print(y_pred.shape)
    pred = y_pred.argmax(dim=1, keepdim=True) # get the index of the max log-probability
    correct_points_train += pred.eq(labels.view_as(pred)).sum().item()
  # print("Train Accuracy: ", (torch.eq(torch.max(y_pred, 1) [1],labels).sum()/len(labels)*100).data.cpu().numpy())
  
  for i,data in enumerate(testDataLoader):
    with torch.no_grad():
      images, labels = data
      images = images.cuda()
      labels = labels.cuda()

      y_pred = model(images)
      fit = loss(y_pred,labels)
      test_loss += fit.item()
      pred = y_pred.argmax(dim=1, keepdim=True) # get the index of the max log-probability
      correct_points_test += pred.eq(labels.view_as(pred)).sum().item()
      # correct_points_test +=  (torch.eq(torch.max(y_pred, 1) [1],labels).sum()).data.cpu().numpy()
  # print("Test Accuracy: ", (torch.eq(torch.max(y_pred, 1) [1],labels).sum()/len(labels)*100).data.cpu().numpy())
      # print('loss:-',fit)

  print(len(trainDataLoader))
  train_loss = train_loss/len(trainDataLoader)
  train_acc = correct_points_train/len(trainDataLoader.dataset) 
  test_loss = test_loss/len(testDataLoader)
  test_acc = correct_points_test/len(testDataLoader.dataset)
  train_loss_hist.append(train_loss)
  test_loss_hist.append(test_loss)
  train_acc_history.append(train_acc) 
  test_acc_history.append(test_acc)

  print('Epoch %s, Train loss %s, Test loss %s'%(epoch, train_loss, test_loss))
  print(f"Train Accuracy: {correct_points_train}/{len(trainDataLoader.dataset)}, {train_acc*100}")
  print(f"Test Accuracy: {correct_points_test}/{len(testDataLoader.dataset)}, {test_acc*100}")

print(train_acc_history)

print(test_acc_history)

print(train_loss_hist)

print(test_loss_hist)

z

# plt.plot(train_loss_hist)
# plt.plot(test_loss_hist)
# plt.legend(["train", "test"])
# plt.title("Accuracy")